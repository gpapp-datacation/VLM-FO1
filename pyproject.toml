[project]
name = "vlm-fo1"
version = "0.1.0"
description = "VLM-FO1: Vision-Language Model with Fine-grained Observation"
requires-python = ">=3.10"
dependencies = [
    "torch>=2.0.0",
    "torchvision",
    "transformers>=4.50.0",
    "timm>=1.0.9",
    "accelerate>=1.0.0",
    "einops",
    "scikit-image",
    "decord2",  # aarch64-compatible replacement for decord
    "safetensors",
    "flash-attn @ https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.3/flash_attn-2.8.3+cu12torch2.9cxx11abiTRUE-cp312-cp312-linux_aarch64.whl",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["vlm_fo1"]
